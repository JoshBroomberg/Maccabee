{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Config Cell\n",
    "\n",
    "# from maccabee.constants import Constants\n",
    "# Constants.DGPSampling.NORMALIZE_SAMPLED_OUTCOME_FUNCTION = True\n",
    "# Constants.DGPSampling.CENTER_SAMPLED_OUTCOME_FUNCTION = True\n",
    "# Constants.DGPSampling.NORMALIZE_SAMPLED_TREATMENT_FUNCTION = True\n",
    "# Constants.DGPSampling.ADJUST_ALIGNMENT = True\n",
    "\n",
    "from maccabee.parameters import ParameterStore\n",
    "import numpy as np\n",
    "\n",
    "def coeff_sampler(self, size=1):\n",
    "    vals = np.random.uniform(low=1, high=10, size=size)\n",
    "    neg_locs = (np.random.random(size=size) < 0.5)\n",
    "    neg_mask = np.full(size, 1)\n",
    "    neg_mask[neg_locs] = -1\n",
    "    return vals*neg_mask\n",
    "\n",
    "def te_sampler(self, size=1):\n",
    "    return np.random.normal(loc=0, scale=3, size=size)\n",
    "    \n",
    "def noise_sampler(self, size=1):\n",
    "    return np.random.normal(scale=0.25, size=size)\n",
    "    \n",
    "ParameterStore.sample_subfunction_constants = coeff_sampler\n",
    "ParameterStore.sample_treatment_effect = te_sampler\n",
    "ParameterStore.sample_outcome_noise = noise_sampler\n",
    "\n",
    "#!python -m pip install -e ../../../../Maccabee > /dev/null"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "R Models\n",
    "**************\n",
    "\n",
    "Installing Dependencies\n",
    "-----------------------\n",
    "\n",
    "Maccabee includes support for benchmarking models written in R. This is experimental functionality which requires the Rpy2 package.\n",
    "\n",
    "In order to use this functionality, you must install Maccabee with the optional R dependencies::\n",
    "    \n",
    "    pip install maccabee[r]\n",
    "    \n",
    "For most users, this should be all that is required to proceed with this tutorial. However, on some systems, configuring Rpy2 may require additional setup. If you encounter problems, there are two options. Either consult the Rpy2 documentation or use Maccabee's pre-built docker image which includes a pre-installed distribution of Rpy2. See :doc:`/installation` for instructions on this.\n",
    "\n",
    "Defining R Models\n",
    "-----------------\n",
    "\n",
    "Defining R models for use with Maccabee proceeds in much the same way as covered in the :doc:`sampled-dgp` tutorial - the definition of a custom class containing the model logic. \n",
    "\n",
    "There are two primary differences. Firstly, the model inherits from :class:`~maccabee.modeling.models.CausalModelR` instead of :class:`~maccabee.modeling.models.CausalModel`. Second, Rpy2 is used in the model to access R functions.\n",
    "\n",
    "R functions can be access by loading existing R packages or loading functions from an R file into a named psuedo-package. In either case, the helper functions return a python object with functions accessible as attribute methods.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    This automatic translation has caveats. For example, `.` separated names are translated to `_` separated. So the `glm.fit` function in the `stats` package will bbe `stats.glm_fit`. See the `Rpy2 docs <https://rpy2.readthedocs.io/en/latest/porting-to-rpy2.html#>`_ for detailed instructions on translating code and accessing return results.\n",
    "\n",
    ".. warning::\n",
    "\n",
    "    The attributes of the :class:`~maccabee.data_generation.generated_data_set.GeneratedDataSet` can generally be passed to the R functions only after conversion to :class:`numpy.ndarrays` instances from :class:`pandas.DataFrame` or :class:`pandas.Series` objects. This is **not** done automatically.\n",
    "    \n",
    "Using an Existing R Package\n",
    "+++++++++++++++++++++++++++\n",
    "\n",
    "The code below defines an R model which uses both Scikit Learn regression and the `Matching` R package to perform a basic Logistic Propensity Score Matching. The Matching package is imported using the :meth:`~maccabee.modeling.models.CausalModelR._import_r_package` instance method.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maccabee.modeling.models import CausalModelR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticPropensityMatchingCausalModel(CausalModelR):\n",
    "    def fit(self):\n",
    "        \n",
    "        # Import the Matching R package\n",
    "        matching = self._import_r_package(\"Matching\")\n",
    "        \n",
    "        # Fit the logistic propensity model.\n",
    "        logistic_model = LogisticRegression(solver='lbfgs', n_jobs=1)\n",
    "        logistic_model.fit(\n",
    "            self.dataset.X.to_numpy(), self.dataset.T.to_numpy())\n",
    "        class_proba = logistic_model.predict_proba(\n",
    "            self.dataset.X.to_numpy())\n",
    "        propensity_scores = class_proba[:, logistic_model.classes_ == 1].flatten()\n",
    "\n",
    "        # Run matching on prop scores using the R match package.\n",
    "        self.match_out = matching.Match(\n",
    "            Y=self.dataset.Y.to_numpy(),\n",
    "            Tr=self.dataset.T.to_numpy(),\n",
    "            X=propensity_scores,\n",
    "            estimand=\"ATT\",\n",
    "            replace=True,\n",
    "            version=\"fast\")\n",
    "\n",
    "    def estimate_ATT(self):\n",
    "        \n",
    "        # Return the ATT by extracting it from the match out result.\n",
    "        return np.array(self.match_out.rx2(\"est\").rx(1,1))[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "With the model defined, we can proceed exactly as in the :doc:`sampled-dgp` tutorial, benchmarking the R model. The results are in line with expectations, the high outcome nonlinearity datasets have larger error across all performance metrics. In each outcome nonlinearity level, the estimator performs better with the more linear treatment mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maccabee.constants import Constants\n",
    "from maccabee.data_sources.data_source_builders import build_random_normal_datasource\n",
    "from maccabee.benchmarking import benchmark_model_using_sampled_dgp_grid\n",
    "import pandas as pd\n",
    "\n",
    "LOW, MEDIUM, HIGH = Constants.AxisLevels.LEVELS\n",
    "\n",
    "param_grid = {\n",
    "    Constants.AxisNames.TREATMENT_NONLINEARITY: [HIGH, LOW],\n",
    "    Constants.AxisNames.OUTCOME_NONLINEARITY: [HIGH, LOW]\n",
    "}\n",
    "\n",
    "normal_data_source = build_random_normal_datasource(\n",
    "    n_covars=5,\n",
    "    n_observations=1000)\n",
    "    \n",
    "results = benchmark_model_using_sampled_dgp_grid(\n",
    "    model_class=LogisticPropensityMatchingCausalModel,\n",
    "    estimand=Constants.Model.ATT_ESTIMAND,\n",
    "    data_source=normal_data_source,\n",
    "    dgp_param_grid=param_grid,\n",
    "    num_dgp_samples=5,\n",
    "    num_sampling_runs_per_dgp=1,\n",
    "    num_samples_from_dgp=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_outcome_nonlinearity</th>\n",
       "      <th>param_treatment_nonlinearity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>AMBP</th>\n",
       "      <th>AMBP (std)</th>\n",
       "      <th>MABP</th>\n",
       "      <th>MABP (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6.008</td>\n",
       "      <td>6.610</td>\n",
       "      <td>8.834</td>\n",
       "      <td>6.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2.604</td>\n",
       "      <td>1.752</td>\n",
       "      <td>9.059</td>\n",
       "      <td>4.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.011</td>\n",
       "      <td>4.107</td>\n",
       "      <td>4.169</td>\n",
       "      <td>11.299</td>\n",
       "      <td>8.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.571</td>\n",
       "      <td>10.111</td>\n",
       "      <td>11.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_outcome_nonlinearity param_treatment_nonlinearity   RMSE  RMSE (std)  \\\n",
       "0                       HIGH                         HIGH  0.051       0.010   \n",
       "1                       HIGH                          LOW  0.050       0.011   \n",
       "2                        LOW                         HIGH  0.039       0.011   \n",
       "3                        LOW                          LOW  0.042       0.015   \n",
       "\n",
       "    AMBP  AMBP (std)    MABP  MABP (std)  \n",
       "0  6.008       6.610   8.834       6.048  \n",
       "1  2.604       1.752   9.059       4.469  \n",
       "2  4.107       4.169  11.299       8.213  \n",
       "3  1.085       0.571  10.111      11.049  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Using Custom R Code\n",
    "+++++++++++++++++++\n",
    "\n",
    "We could also write the R model using an R file. This allows us to avoid some of the complexity of the Rpy2 conversion and also allows for arbitrarily complex R code to be executed. The contents of an R file can be loaded using :meth:`~maccabee.modeling.models.CausalModelR._import_r_file_as_package` instance method.\n",
    "\n",
    "Below, this functionality is used to replicate the model above but running the matching through a custom R function. Notice that extracting the result is simpler in this format than in the python conversion case above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prog = \"\"\"# Custom R program\n",
    "library(\"utils\")\n",
    "capture.output(library(\"Matching\"))\n",
    "\n",
    "p_score_match <- function(Y, Tr, X){\n",
    "    out <- Match(\n",
    "        Y=Y,\n",
    "        Tr=Tr,\n",
    "        X=X,\n",
    "        estimand=\"ATT\",\n",
    "        replace=TRUE,\n",
    "        version=\"fast\")\n",
    "        \n",
    "    return(out[[\"est\"]][1][1])\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"r_prog.R\", \"w\") as file:\n",
    "    file.write(r_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maccabee.modeling.models import CausalModelR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticPropensityMatchingCausalModel(CausalModelR):\n",
    "    def fit(self):\n",
    "        \n",
    "        # Import the custom R file\n",
    "        matching = self._import_r_file_as_package(\"r_prog.R\", \"MatchingCode\")\n",
    "        \n",
    "        # Fit the logistic propensity model.\n",
    "        logistic_model = LogisticRegression(solver='lbfgs', n_jobs=1)\n",
    "        logistic_model.fit(\n",
    "            self.dataset.X.to_numpy(), self.dataset.T.to_numpy())\n",
    "        class_proba = logistic_model.predict_proba(\n",
    "            self.dataset.X.to_numpy())\n",
    "        propensity_scores = class_proba[:, logistic_model.classes_ == 1].flatten()\n",
    "\n",
    "        # Run matching on prop scores using the R match package.\n",
    "        self.att = matching.p_score_match(\n",
    "            Y=self.dataset.Y.to_numpy(),\n",
    "            Tr=self.dataset.T.to_numpy(),\n",
    "            X=propensity_scores)\n",
    "\n",
    "    def estimate_ATT(self):\n",
    "        # Return the ATT by extracting it from the match out result.\n",
    "        return np.array(self.att)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
