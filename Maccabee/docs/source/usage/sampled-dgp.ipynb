{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Hidden Config Cell\n",
    "\n",
    "#!python -m pip install -e ../../../../Maccabee > /dev/null"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Benchmarking with Sampled DGPs\n",
    "******************************\n",
    "\n",
    "This walkthrough previews Maccabee's core functionality - benchmarking causal inference estimators using sampled, synthetic treatment and outcome functions combined with empirical covariate data. You'll find detail on each of the methods and objects mentioned below in the :doc:`/reference` section.\n",
    "\n",
    "The Destination: Sampled DGP Benchmarks\n",
    "---------------------------------------\n",
    "\n",
    "The code below benchmarks a standard linear regression estimate of the Average Treatement Effect (ATE) under 3 distributional settings - low/medium/high outcome mechanism nonlinearity - with treatment assignment mechanism nonlinearity kept low in all three settings.\n",
    "\n",
    "The logical process for this is as follows: we (repeatedly) sample parameter-conformant treatment assignment and outcome functions defined over some covariate data (in this case a standard normal dataset). Each pair of sampled functions is used to generate treatment assignment and potential outcome data based on the empirical covariate data. The estimator being benchmarked is fit to this data, estimates are collected, an estimator performance metrics are calculated based on the ground-truth (which is found using the sampled functions). The performance metrics are averaged over many sampled data generating processes, and many times for each sampled DGP, to account for sources of performance variation in the functions and generated data.\n",
    "\n",
    "Maccabee makes this process extremely easy. The code below executes all of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling DGP 1\n",
      "Sampling DGP 2\n",
      "Sampling DGP 3\n",
      "Sampling DGP 4\n",
      "Sampling DGP 5\n",
      "Sampling DGP 6\n",
      "Sampling DGP 7\n",
      "Sampling DGP 8\n",
      "Sampling DGP 9\n",
      "Sampling DGP 10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 1/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 2/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 3/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 4/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 5/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 6/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 7/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 8/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 9/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 10/10\n",
      "Sampling DGP 1\n",
      "Sampling DGP 2\n",
      "Sampling DGP 3\n",
      "Sampling DGP 4\n",
      "Sampling DGP 5\n",
      "Sampling DGP 6\n",
      "Sampling DGP 7\n",
      "Sampling DGP 8\n",
      "Sampling DGP 9\n",
      "Sampling DGP 10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 1/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 2/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 3/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 4/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 5/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 6/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 7/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 8/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 9/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 10/10\n",
      "Sampling DGP 1\n",
      "Sampling DGP 2\n",
      "Sampling DGP 3\n",
      "Sampling DGP 4\n",
      "Sampling DGP 6\n",
      "Sampling DGP 5\n",
      "Sampling DGP 7\n",
      "Sampling DGP 8\n",
      "Sampling DGP 9\n",
      "Sampling DGP 10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 1/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 2/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 3/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 4/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 5/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 6/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 7/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 8/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 9/10\n",
      "NOTICE: data_analysis_mode is False but the dgp is in data analysis mode.\n",
      "here2\n",
      "Done sampling for DGP 10/10\n"
     ]
    }
   ],
   "source": [
    "from maccabee.constants import Constants\n",
    "from maccabee.data_sources.data_source_builders import build_random_normal_datasource\n",
    "from maccabee.benchmarking import benchmark_model_using_sampled_dgp_grid\n",
    "from maccabee.modeling.models import LinearRegressionCausalModel\n",
    "import pandas as pd\n",
    "\n",
    "LOW, MEDIUM, HIGH = Constants.AxisLevels.LEVELS\n",
    "\n",
    "param_grid = {\n",
    "Constants.AxisNames.TREATMENT_NONLINEARITY: [LOW],\n",
    "Constants.AxisNames.OUTCOME_NONLINEARITY: [HIGH, MEDIUM, LOW]\n",
    "}\n",
    "\n",
    "normal_data_source = build_random_normal_datasource(\n",
    "    n_covars = 20,\n",
    "    n_observations = 1000)\n",
    "    \n",
    "results = benchmark_model_using_sampled_dgp_grid(\n",
    "    model_class=LinearRegressionCausalModel,\n",
    "    estimand=Constants.Model.ATE_ESTIMAND,\n",
    "    data_source=normal_data_source,\n",
    "    dgp_param_grid=param_grid,\n",
    "    num_dgp_samples=10,\n",
    "    num_samples_from_dgp=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_outcome_nonlinearity</th>\n",
       "      <th>param_treatment_nonlinearity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>AMBP</th>\n",
       "      <th>AMBP (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.685</td>\n",
       "      <td>106.228</td>\n",
       "      <td>12.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.468</td>\n",
       "      <td>103.249</td>\n",
       "      <td>6.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.661</td>\n",
       "      <td>135.080</td>\n",
       "      <td>95.781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_outcome_nonlinearity param_treatment_nonlinearity   RMSE  RMSE (std)  \\\n",
       "0                       HIGH                          LOW  0.889       0.685   \n",
       "1                     MEDIUM                          LOW  0.700       0.468   \n",
       "2                        LOW                          LOW  0.665       0.661   \n",
       "\n",
       "      AMBP  AMBP (std)  \n",
       "0  106.228      12.529  \n",
       "1  103.249       6.985  \n",
       "2  135.080      95.781  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The results are consistent with the well known fact that the performance of a linear regression estimator degrades as the non-linearity of the outcome function increases.\n",
    "\n",
    "In the code above, the user has supplied:\n",
    "\n",
    "* A model which will be 'fit' to the data to estimate causal effects - in this case a simple ``LinearRegressionCausalModel``.\n",
    "* A targeted estimated, in this case the ATE.\n",
    "* A ``DataSource``, in this case one that contains 10 independent, random-normal covariates.\n",
    "* A set of parameter combinations in terms of various levels of treatment and outcome function non-linearity.\n",
    "\n",
    "With these choices made, the ``run_sampled_dgp_benchmark`` function can be used\n",
    "to:\n",
    "\n",
    "1. Sample Data Generating Processes, defined over the covariates in the data source, which conform to each of the desired parameter combinations. ``num_dgp_samples`` different DGPs will be sampled and each will be used to generate ``num_data_samples_per_dgp`` different data sets.\n",
    "2. Fit the model and produce the estimated value of the ATE estimand.\n",
    "3. Compare the estimated value to the ground truth and collect performance metrics.\n",
    "\n",
    "With this destination in mind, we can take a few steps back to understand the various components of the benchmarking procedure displayed above.\n",
    "\n",
    "Model Specification\n",
    "-------------------\n",
    "\n",
    "Although it is not displayed above, the first step in using Maccabee is to define a ``Model``. Model's represent causal inference methods, they are fit to a data set and produce an estimate of one or more estimands.\n",
    "\n",
    "The definition of the ``LinearRegressionCausalModel`` used above is below. All models take a `GeneratedDataSet` object at construction time and implement ``fit()`` and ``estimate_*()`` functions. Arbitrary code can be run at initialization, fit and estimate time.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "\n",
    "  class LinearRegressionCausalModel(CausalModel):\n",
    "      def __init__(self, dataset):\n",
    "          self.dataset = dataset\n",
    "          self.model = LinearRegression()\n",
    "          self.data = dataset.observed_data.drop(\"Y\", axis=1)\n",
    "\n",
    "      def fit(self):\n",
    "          self.model.fit(self.data, self.dataset.Y)\n",
    "\n",
    "      def estimate_ATE(self):\n",
    "          # The coefficient on the treatment status\n",
    "          return self.model.coef_[-1]\n",
    "\n",
    "Data Sources\n",
    "-------------\n",
    "\n",
    "The second step is supplying a data source. Fundamentally, a ``DataSource`` is defined by a set of covariate observations. Under the hood, the ``DataSource`` object is responsible for concretizing stochastically defined covariate specification and for the data normalization and management required for DGP sampling. The vast majority of users will not need to worry about the specifics of these processes because the ``data_sources`` module contains a number of ready to use ``DataSource`` generators. These correspond to:\n",
    "\n",
    "1. High-quality empirical data - accessible via ``build_lalonde_datasource()`` and ``build_cpp_datasource()`` (*with more to come*). See the theory paper for a discussion on these datasets .\n",
    "2. Random normal covariates with user-controlled degree of pair-wise correlation. See ``load_random_normal()``.\n",
    "3. Utilities for loading covariates from CSV files and automating the normalization and processing - see ``load_csv()``.\n",
    "\n",
    "For these common use cases, building a ``DataSource`` is as simple as::\n",
    "\n",
    "  from maccabee.data_sources import build_lalonde_datasource\n",
    "  data_source = build_lalonde_datasource()\n",
    "\n",
    "\n",
    "Parameter Specification\n",
    "------------------------\n",
    "\n",
    "The final step in running a sampled DGP benchmark is providing the parameter specification which controls the DGP sampling process. At this stage, specification can only be done by specifying a ``scikit-learn`` style parameter-grid. This is a dictionary where each entry in the dictionary is a parameter name and its value is a list of 'levels' for the parameter - high, medium, or low. Every combination of parameter levels present in the grid will be run in the benchmark.\n",
    "\n",
    "The parameters below are available to control the nature of the sampled DGPs and the resulting distributional setting of the observed data. See the theory paper for a discussion on how these parameters correspond to the axes of the causal inference distributional problem space.\n",
    "\n",
    "#. Outcome Nonlinearity: ``Constants.AxisNames.OUTCOME_NONLINEARITY``\n",
    "#. Treatment Effect Heterogeneity: ``Constants.AxisNames.TE_HETEROGENEITY``\n",
    "#. Treatment Nonlinearity: ``Constants.AxisNames.TREATMENT_NONLINEARITY``\n",
    "#. Percent Treated: ``Constants.AxisNames.PERCENT_TREATED``\n",
    "#. Covariate Overlap: ``Constants.AxisNames.OVERLAP``\n",
    "#. Covariate Balance: ``Constants.AxisNames.BALANCE``\n",
    "#. Outcome/Treatment Function Alignment: ``Constants.AxisNames.ALIGNMENT``\n",
    "\n",
    "The parameter grid below would explore every combination of parameters available in Maccabee::\n",
    "\n",
    "  param_grid = {\n",
    "    Constants.AxisNames.OUTCOME_NONLINEARITY: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.TE_HETEROGENEITY: [HIGH, MEDIUM, LOW]\n",
    "    Constants.AxisNames.TREATMENT_NONLINEARITY: [HIGH, MEDIUM, LOW]\n",
    "    Constants.AxisNames.PERCENT_TREATED: [HIGH, MEDIUM, LOW]\n",
    "    Constants.AxisNames.OVERLAP: [HIGH, MEDIUM, LOW]\n",
    "    Constants.AxisNames.BALANCE: [HIGH, MEDIUM, LOW]\n",
    "    Constants.AxisNames.ALIGNMENT: [HIGH, MEDIUM, LOW]\n",
    "  }\n",
    "\n",
    "Benchmark Results\n",
    "-----------------\n",
    "\n",
    "By default, when running on the ATE estimand, the benchmark function returns the *absolute mean bias percentage* - the absolute value of mean bias across all the estimates from one DGP, averaged across the different DGPs - the root mean squared error, calculated analogously. See the theory paper for detail on these metrics. See the :doc:`../reference` section for details on ITE metrics and supplying custom metric functions.\n",
    "\n",
    "Conclusion\n",
    "----------\n",
    "\n",
    "By specifying different ``Model`` classes, ``DataSource`` instances and combinations of parameter values, users can apply the power of sampled DGP benchmarking to a virtually limitless set of causal inference estimators. For detailed documentation of the objects and methods mentioned above, see the :doc:`/reference` section.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ":class:`DataGeneratingProcesses <maccabee.data_generation.data_generating_process.DataGeneratingProcess>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
