{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbsphinx": "hidden",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Config Cell\n",
    "\n",
    "from maccabee.constants import Constants\n",
    "Constants.DGPSampling.NORMALIZE_SAMPLED_OUTCOME_FUNCTION = True\n",
    "Constants.DGPSampling.CENTER_SAMPLED_OUTCOME_FUNCTION = True\n",
    "Constants.DGPSampling.NORMALIZE_SAMPLED_TREATMENT_FUNCTION = True\n",
    "Constants.DGPSampling.ADJUST_ALIGNMENT = True\n",
    "\n",
    "from maccabee.parameters import ParameterStore\n",
    "import numpy as np\n",
    "\n",
    "def coeff_sampler(self, size=1):\n",
    "    vals = np.random.uniform(low=1, high=10, size=size)\n",
    "    neg_locs = (np.random.random(size=size) < 0.5)\n",
    "    neg_mask = np.full(size, 1)\n",
    "    neg_mask[neg_locs] = -1\n",
    "    return vals*neg_mask\n",
    "\n",
    "def te_sampler(self, size=1):\n",
    "    return np.random.normal(loc=0, scale=3, size=size)\n",
    "    \n",
    "def noise_sampler(self, size=1):\n",
    "    return np.random.normal(scale=0.25, size=size)\n",
    "    \n",
    "ParameterStore.sample_subfunction_constants = coeff_sampler\n",
    "ParameterStore.sample_treatment_effect = te_sampler\n",
    "ParameterStore.sample_outcome_noise = noise_sampler\n",
    "\n",
    "from maccabee.examples.genmatch import LogisticPropensityMatchingCausalModel\n",
    "\n",
    "#!python -m pip install -e ../../../../Maccabee > /dev/null"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Benchmarking with Sampled DGPs\n",
    "******************************\n",
    "\n",
    "This walkthrough previews Maccabee's core functionality - benchmarking causal inference estimators using sampled, synthetic treatment and outcome functions combined with empirical covariate data. You'll find detail on each of the methods and objects mentioned below in the :doc:`/reference`.\n",
    "\n",
    "The Destination: Sampled DGP Benchmarks\n",
    "---------------------------------------\n",
    "\n",
    "The code below benchmarks a standard linear regression estimate of the Average Treatement Effect (ATE) under 3 distributional settings - low/medium/high outcome mechanism nonlinearity - with treatment assignment mechanism nonlinearity kept low in all three settings.\n",
    "\n",
    "The logical process for this is as follows - we (repeatedly) sample parameter-conformant treatment assignment and outcome functions defined over some covariate data (in this case a standard normal dataset). Each pair of sampled functions is used to generate treatment assignment and potential outcome data based on the empirical covariate data. The estimator being benchmarked is fit to this data, estimates are collected, an estimator performance metrics are calculated based on the ground-truth (which is found using the sampled functions). The performance metrics are averaged over many sampled data generating processes, and many times for each sampled DGP, to account for sources of performance variation in the functions and generated data.\n",
    "\n",
    "Maccabee makes this process extremely easy. The code below executes all of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from maccabee.constants import Constants\n",
    "from maccabee.data_sources.data_source_builders import build_random_normal_datasource\n",
    "from maccabee.benchmarking import benchmark_model_using_sampled_dgp_grid\n",
    "from maccabee.modeling.models import LinearRegressionCausalModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "LOW, MEDIUM, HIGH = Constants.AxisLevels.LEVELS\n",
    "\n",
    "param_grid = {\n",
    "Constants.AxisNames.TREATMENT_NONLINEARITY: [LOW],\n",
    "Constants.AxisNames.OUTCOME_NONLINEARITY: [HIGH, MEDIUM, LOW]\n",
    "}\n",
    "\n",
    "normal_data_source = build_random_normal_datasource(\n",
    "    n_covars=5,\n",
    "    n_observations=1000)\n",
    "    \n",
    "results = benchmark_model_using_sampled_dgp_grid(\n",
    "    model_class=LinearRegressionCausalModel,\n",
    "    estimand=Constants.Model.ATE_ESTIMAND,\n",
    "    data_source=normal_data_source,\n",
    "    dgp_param_grid=param_grid,\n",
    "    num_dgp_samples=10,\n",
    "    num_sampling_runs_per_dgp=5,\n",
    "    num_samples_from_dgp=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_outcome_nonlinearity</th>\n",
       "      <th>param_treatment_nonlinearity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>AMBP</th>\n",
       "      <th>AMBP (std)</th>\n",
       "      <th>MABP</th>\n",
       "      <th>MABP (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.030</td>\n",
       "      <td>17.892</td>\n",
       "      <td>25.949</td>\n",
       "      <td>21.771</td>\n",
       "      <td>25.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.644</td>\n",
       "      <td>3.316</td>\n",
       "      <td>3.654</td>\n",
       "      <td>3.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_outcome_nonlinearity param_treatment_nonlinearity   RMSE  RMSE (std)  \\\n",
       "0                       HIGH                          LOW  0.081       0.030   \n",
       "1                     MEDIUM                          LOW  0.043       0.020   \n",
       "2                        LOW                          LOW  0.017       0.001   \n",
       "\n",
       "     AMBP  AMBP (std)    MABP  MABP (std)  \n",
       "0  17.892      25.949  21.771      25.519  \n",
       "1   2.644       3.316   3.654       3.986  \n",
       "2   0.100       0.067   0.995       0.445  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The results are consistent with the well known fact that the performance of a linear regression estimator degrades as the non-linearity of the outcome function increases. This is evident from all three performance metrics, although the variance of the AMBP and MABP appears too large for a reliable conclusion based on these values.\n",
    "\n",
    "In the code above, the user has supplied:\n",
    "\n",
    "* A model which will be 'fit' to the data to estimate causal effects - in this case a simple :class:`~maccabee.modeling.models.LinearRegressionCausalModel` which is supplied as an example model with the Maccabee package.\n",
    "* A targeted estimated, in this case the ATE estimand (specified using the ATE value in the ``Model`` constants group in :class:`~maccabee.constants.Constants`).\n",
    "* A :class:`~maccabee.data_sources.data_sources.DataSource`, in this case one that contains 1000 observations of 5 independent, standard-normal covariates.\n",
    "* A grid of parameter which specifies the combinations of parameters as various levels of treatment and outcome function non-linearity.\n",
    "\n",
    "With these choices made, the :func:`~maccabee.benchmarking.benchmarking.benchmark_model_using_sampled_dgp_grid` function can be used to:\n",
    "\n",
    "1. Sample Data Generating Processes, defined over the covariates in the data source, which conform to each of the desired parameter combinations.\n",
    "2. ``num_dgp_samples`` different DGPs will be sampled and each will be used to generate ``num_samples_from_dgp`` different data sets.\n",
    "3. Fit the model and produce the estimated value of the ATE estimand.\n",
    "4. Compare the estimated value to the ground truth and collect performance metrics.\n",
    "5. Repeat steps 2-4 ``num_sampling_runs_per_dgp`` times to determine the variance of the metric estimates (recall that each metric is defined over a sample of estimate values).\n",
    "\n",
    "With this procedure in mind, we can take a few steps back to understand the various components which are mentioned above.\n",
    "\n",
    "The Components of Sampled DGP Benchmarks\n",
    "----------------------------------------\n",
    "\n",
    "Model Specification\n",
    "+++++++++++++++++++\n",
    "\n",
    "Although it is not explicitly displayed above, the first step in using Maccabee is to define a :class:`~maccabee.modeling.models.CausalModel`. The :class:`~maccabee.modeling.models.CausalModel` class is used to make an arbitrary causal inference method compatible with Maccabee.\n",
    "\n",
    "The code which defines the :class:`~maccabee.modeling.models.LinearRegressionCausalModel` used above is presented below. You can create an analogous model wrapping any code by inheriting from :class:`~maccabee.modeling.models.CausalModel` just like the :class:`~maccabee.modeling.models.LinearRegressionCausalModel` and overriding the relevant methods.\n",
    "\n",
    "All models take a :class:`~maccabee.data_generation.generated_data_set.GeneratedDataSet` object at construction time and implement ``fit()`` and ``estimate_*()`` functions. Arbitrary code can be run at fit and estimate time. Fit is run exactly once per model instance prior to estimates. See the docs for the :class:`~maccabee.modeling.models.CausalModel` for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from maccabee.modeling.models import CausalModel\n",
    "\n",
    "\n",
    "class LinearRegressionCausalModel(CausalModel):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.model = LinearRegression()\n",
    "        self.data = dataset.observed_data.drop(\"Y\", axis=1)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the linear regression model.\n",
    "        \"\"\"\n",
    "        self.model.fit(self.data, self.dataset.Y)\n",
    "\n",
    "    def estimate_ATE(self):\n",
    "        \"\"\"\n",
    "        Return the co-efficient on the treatment status variable as the\n",
    "        ATE.\n",
    "        \"\"\"\n",
    "        # The coefficient on the treatment status\n",
    "        return self.model.coef_[-1]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Data Sources\n",
    "++++++++++++\n",
    "\n",
    "The second step is supplying a data source. Fundamentally, a :class:`~maccabee.data_sources.data_sources.DataSource` is defined by a set of covariate observations. Under the hood, the :class:`~maccabee.data_sources.data_sources.DataSource` object is responsible for concretizing stochastically defined covariate specification and for the data normalization and management required for DGP sampling. The vast majority of users will not need to worry about the specifics of these processes because the :mod:`~maccabee.data_sources.data_source_builders` module contains a number of convenient :class:`~maccabee.data_sources.data_sources.DataSource` generator functions. These correspond to:\n",
    "\n",
    "1. High-quality empirical data - accessible via :func:`~maccabee.data_sources.data_source_builders.build_lalonde_datasource` and :func:`~maccabee.data_sources.data_source_builders.build_cpp_datasource` (*with more to come*). See the theory paper for a discussion on these datasets .\n",
    "2. Random normal covariates with user-controlled degree of pair-wise correlation. See :func:`~maccabee.data_sources.data_source_builders.build_random_normal_datasource`.\n",
    "3. Utilities for loading covariates from CSV files and automating the normalization and processing - see :func:`~maccabee.data_sources.data_source_builders.build_csv_datasource`.\n",
    "\n",
    "For these common use cases, building a :class:`~maccabee.data_sources.data_sources.DataSource` is as simple as using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maccabee.data_sources import build_lalonde_datasource\n",
    "data_source = build_lalonde_datasource()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Parameter Specification\n",
    "+++++++++++++++++++++++\n",
    "\n",
    "The final step in running a sampled DGP benchmark is providing the parameter specification which controls the DGP sampling process. At this stage, specification can only be done by specifying a ``scikit-learn`` style parameter-grid. See the :func:`~maccabee.benchmarking.benchmarking.benchmark_model_using_sampled_dgp_grid` function for more detail on this specification format.\n",
    "\n",
    "The valid parameters are in the ``AxisNames`` constant group in :class:`~maccabee.constants.Constants`. The listing of the parameters can be accessed using the ``all()`` helper method defined for each constant group in :class:`~maccabee.constants.Constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OUTCOME_NONLINEARITY': 'OUTCOME_NONLINEARITY',\n",
       " 'TREATMENT_NONLINEARITY': 'TREATMENT_NONLINEARITY',\n",
       " 'PERCENT_TREATED': 'PERCENT_TREATED',\n",
       " 'OVERLAP': 'OVERLAP',\n",
       " 'BALANCE': 'BALANCE',\n",
       " 'ALIGNMENT': 'ALIGNMENT',\n",
       " 'TE_HETEROGENEITY': 'TE_HETEROGENEITY'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from maccabee.constants import Constants\n",
    "Constants.AxisNames.all()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Each of these parameters correspond to a :term:`distributional problem space axis` and therefore contribute to controling the :term:`distributional setting` of the observed data produced by the sampled DGPs. See the theory paper for a discussion on how these parameters correspond to the axes of the causal inference distributional problem space.\n",
    "\n",
    "Thus, the parameter grid below would explore every combination of parameters available in Maccabee - exploring the full :term:`distributional problem space`. It is highly likely that a much smaller subset of combinations would suffice for the purpose of most evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW, MEDIUM, HIGH = Constants.AxisLevels.LEVELS\n",
    "\n",
    "complete_param_grid = {\n",
    "    Constants.AxisNames.OUTCOME_NONLINEARITY: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.TE_HETEROGENEITY: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.TREATMENT_NONLINEARITY: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.PERCENT_TREATED: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.OVERLAP: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.BALANCE: [HIGH, MEDIUM, LOW],\n",
    "    Constants.AxisNames.ALIGNMENT: [HIGH, MEDIUM, LOW]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Analyzing Benchmark Results\n",
    "---------------------------\n",
    "\n",
    "By default, when running on the ATE estimand, the benchmark function collects and returns all of the performance metrics from the :mod:`~maccabee.modeling.performance_metrics` module. See the documentation for that module for more detail on the metrics themselves.\n",
    "\n",
    "The metrics are returned as a dictionary of lists, with keys corresponding to the metric names and list entries for the average metric value at each parameter combination (along with the standard deviation for the metric value across the set of sampled dgps). This dictionary also includes lists that contain the corresponding parameter values.\n",
    "\n",
    "The upshot is that it is possible to build a :class:`~pandas.DataFrame` object and then use this object to explore the metric values for every parameter combination. This is exactly what was done above. Building the :class:`~pandas.DataFrame` is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_outcome_nonlinearity</th>\n",
       "      <th>param_treatment_nonlinearity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>AMBP</th>\n",
       "      <th>AMBP (std)</th>\n",
       "      <th>MABP</th>\n",
       "      <th>MABP (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.030</td>\n",
       "      <td>17.892</td>\n",
       "      <td>25.949</td>\n",
       "      <td>21.771</td>\n",
       "      <td>25.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.644</td>\n",
       "      <td>3.316</td>\n",
       "      <td>3.654</td>\n",
       "      <td>3.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_outcome_nonlinearity param_treatment_nonlinearity   RMSE  RMSE (std)  \\\n",
       "0                       HIGH                          LOW  0.081       0.030   \n",
       "1                     MEDIUM                          LOW  0.043       0.020   \n",
       "2                        LOW                          LOW  0.017       0.001   \n",
       "\n",
       "     AMBP  AMBP (std)    MABP  MABP (std)  \n",
       "0  17.892      25.949  21.771      25.519  \n",
       "1   2.644       3.316   3.654       3.986  \n",
       "2   0.100       0.067   0.995       0.445  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "\n",
    "As you can see, not all metrics may be interesting for all use cases, especially if the sample size is too small to produce a meaningfully narrow metric estimate interval. This appears to be the case for the ``MABP`` and ``AMBP`` estimates in the high outcome nonlineairty setting in the table above.\n",
    "\n",
    "The :class:`~pandas.DataFrame` can be used to select, sort, and filter the metrics and result rows - in this case, removing the result row with large intervals and the MABP metric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_outcome_nonlinearity</th>\n",
       "      <th>param_treatment_nonlinearity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>AMBP</th>\n",
       "      <th>AMBP (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.644</td>\n",
       "      <td>3.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_outcome_nonlinearity param_treatment_nonlinearity   RMSE  RMSE (std)  \\\n",
       "1                     MEDIUM                          LOW  0.043       0.020   \n",
       "2                        LOW                          LOW  0.017       0.001   \n",
       "\n",
       "    AMBP  AMBP (std)  \n",
       "1  2.644       3.316  \n",
       "2  0.100       0.067  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\n",
    "    results_df[\"param_outcome_nonlinearity\"]!=HIGH\n",
    "].drop([\"MABP\", \"MABP (std)\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In order to run a Maccabee benchmark, you will need to supply a :class:`~maccabee.modeling.models.CausalModel` class, a :class:`~maccabee.data_sources.data_sources.DataSource` instance and a combination of parameter values. The flexibility of the model and data source classes mean that users can apply the power of sampled DGP benchmarking to a virtually limitless set of causal inference estimators and source covariate datasets. For detailed documentation of the objects and methods mentioned above, see the :doc:`/reference`."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
