{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Config Cell\n",
    "\n",
    "#!python -m pip install -e ../../../../Maccabee > /dev/null"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Benchmarking with a Concrete DGP\n",
    "********************************\n",
    "\n",
    "The :doc:`sampled-dgp` section demonstrated how to evaluate a causal estimator using DGPs sampled from a location in the :term:`distributional problem space`. While this approach is central to Maccabee's benchmarking philosophy, it is also possible to use this package to run benchmarks using concretely specified DGPs. This will be useful if you want to compare sampled DGP results to previous results from concrete DGPs or if you want to make use of Maccabee's result analysis and parallelization tools.\n",
    "\n",
    "The Maccabee DSL for Specifying Concrete DGPs\n",
    "------------------------------------------------\n",
    "\n",
    "Using a concrete DGP requires manual specification of the data generating process. Maccabee provides a light :term:`DSL <dsl>` - a domain specific language - which wraps standard python methods to make custom DGP specification as easy as possible. The DSL  allows Maccabee to handle most of the boilerplate operations involved in sampling from the DGP and ensures the compatibility of the DGP with the rest of the functionality in the package.\n",
    "\n",
    "The code below specifies a concrete DGP with three normally distributed covariates, a linear outcome function and a linear treatment assignment logit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from maccabee.data_generation import ConcreteDataGeneratingProcess, data_generating_method\n",
    "from maccabee.constants import Constants\n",
    "from maccabee.data_generation.utils import evaluate_expression\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "DGPVariables = Constants.DGPVariables\n",
    "\n",
    "class CustomConcreteDataGeneratingProcess(ConcreteDataGeneratingProcess):\n",
    "    def __init__(self, n_observations):\n",
    "\n",
    "        super().__init__(n_observations, data_analysis_mode=False)\n",
    "\n",
    "        # Three covariates - A, B and C.\n",
    "        self.n_vars = 3\n",
    "        self.covar_names = [\"A\", \"B\", \"C\"]\n",
    "        self.A, self.B, self.C  = sp.symbols(self.covar_names)\n",
    "\n",
    "        # Linear treatment assignment logit\n",
    "        self.treatment_assignment_function = 1/(1 + sp.exp(-1*(5*self.A + -7*self.B)))\n",
    "\n",
    "        # Linear untreated outcome function.\n",
    "        self.base_outcome_function = 6*self.C\n",
    "\n",
    "    @data_generating_method(DGPVariables.COVARIATES_NAME, [])\n",
    "    def _generate_observed_covars(self, input_vars):\n",
    "        X = np.random.normal(loc=0.0, scale=1.0, size=(\n",
    "          self.n_observations, self.n_vars))\n",
    "\n",
    "        return pd.DataFrame(X, columns=self.covar_names)\n",
    "\n",
    "    @data_generating_method(DGPVariables.PROPENSITY_SCORE_NAME,\n",
    "                          [DGPVariables.COVARIATES_NAME])\n",
    "    def _generate_true_propensity_scores(self, input_vars):\n",
    "        observed_covariate_data = input_vars[DGPVariables.COVARIATES_NAME]\n",
    "\n",
    "        return evaluate_expression(\n",
    "          self.treatment_assignment_function,\n",
    "          observed_covariate_data)\n",
    "\n",
    "    @data_generating_method(\n",
    "      DGPVariables.POTENTIAL_OUTCOME_WITHOUT_TREATMENT_NAME,\n",
    "      [DGPVariables.COVARIATES_NAME])\n",
    "    def _generate_outcomes_without_treatment(self, input_vars):\n",
    "        observed_covariate_data = input_vars[DGPVariables.COVARIATES_NAME]\n",
    "\n",
    "        return evaluate_expression(\n",
    "          self.base_outcome_function,\n",
    "          observed_covariate_data)\n",
    "\n",
    "    @data_generating_method(DGPVariables.OUTCOME_NOISE_NAME, [])\n",
    "    def _generate_outcome_noise_samples(self, input_vars):\n",
    "        return np.random.normal(loc=0, scale=0.25, size=self.n_observations)\n",
    "\n",
    "    @data_generating_method(\n",
    "      DGPVariables.TREATMENT_EFFECT_NAME,\n",
    "      [DGPVariables.COVARIATES_NAME])\n",
    "    def _generate_treatment_effects(self, input_vars):\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Note that the ``CustomConcreteDataGeneratingProcess`` inherits from :class:`~maccabee.data_generation.data_generating_process.ConcreteDataGeneratingProcess` and overrides the parent class's ``_generate_*()`` methods. Each ``_generate_*()`` method in the class is decorated using :func:`~maccabee.data_generation.data_generating_process.data_generating_method`. The decorator is used to indicate the :term:`DGP variable <dgp variable>` that the decorated method produces and the DGP variables on which it depends. The variables on which a method depends are automatically passed into the method at execution time. For more detail on the Maccabee DSL see the :mod:`maccabee.data_generation.data_generating_process` module reference.\n",
    "\n",
    "Generating Data\n",
    "---------------\n",
    "\n",
    "With the DGP specified, we can perform a quick manual data generation to ensure things are working the way we intended.\n",
    "\n",
    "First, we instantiate the DGP (supplying the desired number of observations) and then generate a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_dgp = CustomConcreteDataGeneratingProcess(n_observations=100)\n",
    "dataset = concrete_dgp.generate_dataset()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "We can then look at the observed data property of the sampled :class:`~maccabee.data_generation.generated_data_set.GeneratedDataSet` instance. The observed data contains the three covariates and a treatment and outcome status. Probing the ``ATE`` property of the dataset reveals the expected average treatment effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.616131</td>\n",
       "      <td>-0.764650</td>\n",
       "      <td>-0.191657</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.937014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577143</td>\n",
       "      <td>-0.209127</td>\n",
       "      <td>-0.554967</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.993029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.247293</td>\n",
       "      <td>1.054256</td>\n",
       "      <td>-0.307911</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.812844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.645216</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>-1.083359</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.651235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.915464</td>\n",
       "      <td>0.672721</td>\n",
       "      <td>0.082086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C  T         Y\n",
       "0 -1.616131 -0.764650 -0.191657  0 -0.937014\n",
       "1 -0.577143 -0.209127 -0.554967  1 -0.993029\n",
       "2 -0.247293  1.054256 -0.307911  0 -1.812844\n",
       "3 -0.645216  0.106769 -1.083359  0 -6.651235\n",
       "4  0.915464  0.672721  0.082086  0  0.801945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.observed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground truth\n",
    "dataset.ATE "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Given the linearity of the model, we would expect a logistic regression to recover the true ATE and, indeed, it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9379849734528494"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from maccabee.modeling.models import LinearRegressionCausalModel\n",
    "\n",
    "# Build and fit model\n",
    "model = LinearRegressionCausalModel(dataset)\n",
    "model.fit()\n",
    "\n",
    "# estimate\n",
    "model.estimate_ATE() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Running a Benchmark\n",
    "--------------------\n",
    "\n",
    "We're now ready to run a benchmark. The code is only loosely analogous to the sample-based benchmark in the :doc:`sampled-dgp` section. We still supply a model class, estimand and number of samples to take from the DGP. But the concrete specification of the DGP means we only supply the DGP instance rather than sampling parameters and a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maccabee.benchmarking import benchmark_model_using_concrete_dgp\n",
    "\n",
    "aggregated_results, raw_results, _, _ = benchmark_model_using_concrete_dgp(\n",
    "  dgp=concrete_dgp,\n",
    "  model_class=LinearRegressionCausalModel,\n",
    "  estimand=Constants.Model.ATE_ESTIMAND,\n",
    "  num_sampling_runs_per_dgp=10,\n",
    "  num_samples_from_dgp=250)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "As one would expect for such a simple DGP and distributional setting, the RMSE and AMBP are both close to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.083, 0.229)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_results[\"RMSE\"], aggregated_results[\"AMBP\"] "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
