{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from CauseML.parameters import build_parameters_from_metric_levels\n",
    "from CauseML.constants import Constants\n",
    "from CauseML.data_generation import DataGeneratingProcessWrapper\n",
    "import CauseML.data_sources as data_sources\n",
    "from CauseML.utilities import extract_treat_and_control_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp():\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=(50, 25, 10),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        batch_size='auto',\n",
    "        learning_rate='constant',\n",
    "        learning_rate_init=0.001,\n",
    "        power_t=0.5,\n",
    "        max_iter=1000,\n",
    "        shuffle=True,\n",
    "        random_state=1,\n",
    "        tol=0.0001,\n",
    "        verbose=False,\n",
    "        warm_start=False,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.10,\n",
    "        epsilon=1e-08,\n",
    "        n_iter_no_change=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    prop_score=0.5,\n",
    "    n_covars=20,\n",
    "    n_observations=50000):\n",
    "    \n",
    "    covar_data_source = data_sources.load_random_normal_covariates(\n",
    "        n_covars=n_covars,\n",
    "        n_observations=n_observations,\n",
    "        partial_correlation_degree=0.1)\n",
    "\n",
    "    dgp_params = build_parameters_from_metric_levels({\n",
    "        Constants.MetricNames.TREATMENT_NONLINEARITY: Constants.MetricLevels.LOW,\n",
    "        Constants.MetricNames.OUTCOME_NONLINEARITY: Constants.MetricLevels.LOW,\n",
    "        Constants.MetricNames.TE_HETEROGENEITY: Constants.MetricLevels.LOW\n",
    "    })\n",
    "    \n",
    "    dgp_params.set_parameter(\"MIN_PROPENSITY_SCORE\", 0.001)\n",
    "    dgp_params.set_parameter(\"MAX_PROPENSITY_SCORE\", 0.9999)\n",
    "    dgp_params.set_parameter(\"TREATMENT_EFFECT_HETEROGENEITY\", 0.05)\n",
    "    dgp_params.set_parameter(\"OUTCOME_NOISE_TAIL_THICKNESS\", 300)\n",
    "    dgp_params.set_parameter(\"TARGET_PROPENSITY_SCORE\", prop_score)\n",
    "#     dgp_params.set_parameter(\"TREAT_MECHANISM_COVARIATE_SELECTION_PROBABILITY\",\n",
    "#                              {\n",
    "#                                 \"LINEAR\": 1,\n",
    "#                                 \"POLY_QUAD\": 0.0,\n",
    "#                                 \"POLY_CUBIC\": 0.0,\n",
    "#                                 \"STEP_JUMP\": 0,\n",
    "#                                 \"STEP_KINK\": 0,\n",
    "#                                 \"INTERACTION_TWO_WAY\": 0,\n",
    "#                                 \"INTERACTION_THREE_WAY\": 0\n",
    "#                              })\n",
    "#     dgp_params.set_parameter(\"OUTCOME_MECHANISM_COVARIATE_SELECTION_PROBABILITY\",\n",
    "#                              {\n",
    "#                                 \"LINEAR\": 1,\n",
    "#                                 \"POLY_QUAD\": 0.0,\n",
    "#                                 \"POLY_CUBIC\": 0.0,\n",
    "#                                 \"STEP_JUMP\": 0.05,\n",
    "#                                 \"STEP_KINK\": 0,\n",
    "#                                 \"INTERACTION_TWO_WAY\": 0,\n",
    "#                                 \"INTERACTION_THREE_WAY\": 0\n",
    "#                              })\n",
    "\n",
    "    dgp_wrapper = DataGeneratingProcessWrapper(\n",
    "        parameters=dgp_params, data_source=covar_data_source)\n",
    "\n",
    "    dgp_wrapper.sample_dgp()\n",
    "\n",
    "    _ = dgp_wrapper.generate_data()\n",
    "    \n",
    "    obs_data = dgp_wrapper.get_observed_data()\n",
    "    oracle_data = dgp_wrapper.get_oracle_data()\n",
    "    \n",
    "    return obs_data, oracle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>...</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25263</th>\n",
       "      <td>1</td>\n",
       "      <td>0.244919</td>\n",
       "      <td>0.074285</td>\n",
       "      <td>-0.458034</td>\n",
       "      <td>-0.042549</td>\n",
       "      <td>-0.062885</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>-0.040410</td>\n",
       "      <td>0.035290</td>\n",
       "      <td>0.105273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392851</td>\n",
       "      <td>-0.111192</td>\n",
       "      <td>0.212043</td>\n",
       "      <td>-0.120007</td>\n",
       "      <td>-0.217505</td>\n",
       "      <td>-0.089801</td>\n",
       "      <td>-0.276038</td>\n",
       "      <td>-0.252135</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>-0.047995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40631</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.315248</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.072061</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>-0.154855</td>\n",
       "      <td>-0.242792</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.284953</td>\n",
       "      <td>-0.167545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100991</td>\n",
       "      <td>-0.468550</td>\n",
       "      <td>0.033444</td>\n",
       "      <td>-0.100431</td>\n",
       "      <td>0.362265</td>\n",
       "      <td>-0.056477</td>\n",
       "      <td>0.339392</td>\n",
       "      <td>0.145366</td>\n",
       "      <td>0.252079</td>\n",
       "      <td>0.055075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.225186</td>\n",
       "      <td>-0.172144</td>\n",
       "      <td>-0.060696</td>\n",
       "      <td>0.261099</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>-0.260881</td>\n",
       "      <td>-0.152487</td>\n",
       "      <td>0.197730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257062</td>\n",
       "      <td>0.227827</td>\n",
       "      <td>0.270138</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>-0.257160</td>\n",
       "      <td>-0.343878</td>\n",
       "      <td>0.068046</td>\n",
       "      <td>-0.248606</td>\n",
       "      <td>0.300576</td>\n",
       "      <td>0.129520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.166874</td>\n",
       "      <td>-0.126949</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>-0.333142</td>\n",
       "      <td>-0.198859</td>\n",
       "      <td>0.187568</td>\n",
       "      <td>-0.122312</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.162323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113884</td>\n",
       "      <td>-0.277389</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>-0.174227</td>\n",
       "      <td>-0.035104</td>\n",
       "      <td>0.345181</td>\n",
       "      <td>-0.023110</td>\n",
       "      <td>-0.107066</td>\n",
       "      <td>0.189049</td>\n",
       "      <td>-0.308572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.037702</td>\n",
       "      <td>-0.176896</td>\n",
       "      <td>0.309902</td>\n",
       "      <td>0.133364</td>\n",
       "      <td>0.180438</td>\n",
       "      <td>-0.037667</td>\n",
       "      <td>-0.146259</td>\n",
       "      <td>-0.088651</td>\n",
       "      <td>-0.044983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380661</td>\n",
       "      <td>0.139664</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>-0.630373</td>\n",
       "      <td>-0.195870</td>\n",
       "      <td>0.190585</td>\n",
       "      <td>-0.270072</td>\n",
       "      <td>0.115190</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T         Y        X0        X1        X2        X3        X4  \\\n",
       "25263  1  0.244919  0.074285 -0.458034 -0.042549 -0.062885  0.013582   \n",
       "40631  0 -0.315248  0.020221  0.072061  0.037275 -0.154855 -0.242792   \n",
       "9751   0  0.590284  0.225186 -0.172144 -0.060696  0.261099  0.003667   \n",
       "2817   0 -1.166874 -0.126949  0.029927 -0.333142 -0.198859  0.187568   \n",
       "35873  1 -2.037702 -0.176896  0.309902  0.133364  0.180438 -0.037667   \n",
       "\n",
       "             X5        X6        X7  ...       X10       X11       X12  \\\n",
       "25263 -0.040410  0.035290  0.105273  ...  0.392851 -0.111192  0.212043   \n",
       "40631  0.031115  0.284953 -0.167545  ... -0.100991 -0.468550  0.033444   \n",
       "9751  -0.260881 -0.152487  0.197730  ... -0.257062  0.227827  0.270138   \n",
       "2817  -0.122312  0.140900  0.162323  ...  0.113884 -0.277389  0.000654   \n",
       "35873 -0.146259 -0.088651 -0.044983  ... -0.380661  0.139664  0.183469   \n",
       "\n",
       "            X13       X14       X15       X16       X17       X18       X19  \n",
       "25263 -0.120007 -0.217505 -0.089801 -0.276038 -0.252135  0.012416 -0.047995  \n",
       "40631 -0.100431  0.362265 -0.056477  0.339392  0.145366  0.252079  0.055075  \n",
       "9751   0.107714 -0.257160 -0.343878  0.068046 -0.248606  0.300576  0.129520  \n",
       "2817  -0.174227 -0.035104  0.345181 -0.023110 -0.107066  0.189049 -0.308572  \n",
       "35873  0.472300 -0.630373 -0.195870  0.190585 -0.270072  0.115190 -0.157574  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_data, unobservable_data = generate_data(prop_score=0.5)\n",
    "observed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit(P(T|X))</th>\n",
       "      <th>P(T|X)</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>TE</th>\n",
       "      <th>TRANSFORMED_X0</th>\n",
       "      <th>TRANSFORMED_X1</th>\n",
       "      <th>TRANSFORMED_X2</th>\n",
       "      <th>TRANSFORMED_X3</th>\n",
       "      <th>TRANSFORMED_X4</th>\n",
       "      <th>...</th>\n",
       "      <th>TRANSFORMED_X23</th>\n",
       "      <th>TRANSFORMED_X24</th>\n",
       "      <th>TRANSFORMED_X25</th>\n",
       "      <th>TRANSFORMED_X26</th>\n",
       "      <th>TRANSFORMED_X27</th>\n",
       "      <th>TRANSFORMED_X28</th>\n",
       "      <th>TRANSFORMED_X29</th>\n",
       "      <th>TRANSFORMED_X30</th>\n",
       "      <th>TRANSFORMED_X31</th>\n",
       "      <th>NOISE(Y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25263</th>\n",
       "      <td>2.095762</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>1.174919</td>\n",
       "      <td>0.244919</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.009053</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.020734</td>\n",
       "      <td>0.070537</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40631</th>\n",
       "      <td>-1.669935</td>\n",
       "      <td>0.158433</td>\n",
       "      <td>-0.315248</td>\n",
       "      <td>-1.245248</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>-0.023992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.023792</td>\n",
       "      <td>-0.011097</td>\n",
       "      <td>-0.005294</td>\n",
       "      <td>-0.002121</td>\n",
       "      <td>-0.006630</td>\n",
       "      <td>-0.019562</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>1.631290</td>\n",
       "      <td>0.836346</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>-0.339716</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.017005</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.070632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.055953</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>-0.006312</td>\n",
       "      <td>-0.005398</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.045393</td>\n",
       "      <td>-0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>-0.801068</td>\n",
       "      <td>0.309797</td>\n",
       "      <td>-1.166874</td>\n",
       "      <td>-2.096874</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.016249</td>\n",
       "      <td>-0.021056</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>-0.017721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>-0.133303</td>\n",
       "      <td>-0.004609</td>\n",
       "      <td>-0.003970</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>-0.002753</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.021282</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>-0.588698</td>\n",
       "      <td>0.356934</td>\n",
       "      <td>-1.107702</td>\n",
       "      <td>-2.037702</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>-0.022643</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.017849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>-0.047725</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>-0.007994</td>\n",
       "      <td>-0.028511</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       logit(P(T|X))    P(T|X)        Y0        Y1    TE  TRANSFORMED_X0  \\\n",
       "25263       2.095762  0.890491  1.174919  0.244919 -0.93       -0.009053   \n",
       "40631      -1.669935  0.158433 -0.315248 -1.245248 -0.93        0.014409   \n",
       "9751        1.631290  0.836346  0.590284 -0.339716 -0.93       -0.017005   \n",
       "2817       -0.801068  0.309797 -1.166874 -2.096874 -0.93       -0.013960   \n",
       "35873      -0.588698  0.356934 -1.107702 -2.037702 -0.93        0.003869   \n",
       "\n",
       "       TRANSFORMED_X1  TRANSFORMED_X2  TRANSFORMED_X3  TRANSFORMED_X4  ...  \\\n",
       "25263        0.009508        0.005478        0.005423        0.076477  ...   \n",
       "40631        0.002588        0.003445        0.001476       -0.023992  ...   \n",
       "9751         0.028824        0.020977        0.016439        0.070632  ...   \n",
       "2817        -0.016249       -0.021056       -0.009267       -0.017721  ...   \n",
       "35873       -0.022643        0.011948       -0.012913       -0.017849  ...   \n",
       "\n",
       "       TRANSFORMED_X23  TRANSFORMED_X24  TRANSFORMED_X25  TRANSFORMED_X26  \\\n",
       "25263         0.000737        -0.000468        -0.020734         0.070537   \n",
       "40631        -0.001173        -0.000251         0.023792        -0.011097   \n",
       "9751          0.001384         0.000381         0.055953         0.026510   \n",
       "2817          0.001136        -0.000599        -0.133303        -0.004609   \n",
       "35873        -0.000315         0.000508        -0.068072        -0.047725   \n",
       "\n",
       "       TRANSFORMED_X27  TRANSFORMED_X28  TRANSFORMED_X29  TRANSFORMED_X30  \\\n",
       "25263        -0.000261         0.008250         0.042139         0.011745   \n",
       "40631        -0.005294        -0.002121        -0.006630        -0.019562   \n",
       "9751         -0.006312        -0.005398         0.015837         0.013887   \n",
       "2817         -0.003970         0.002392        -0.002753         0.001896   \n",
       "35873        -0.002419        -0.007994        -0.028511         0.034040   \n",
       "\n",
       "       TRANSFORMED_X31  NOISE(Y)  \n",
       "25263         0.007031     0.078  \n",
       "40631        -0.005414     0.170  \n",
       "9751          0.045393    -0.090  \n",
       "2817          0.021282     0.173  \n",
       "35873         0.025449     0.174  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unobservable_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ITE(ITE_true, ITE_pred):\n",
    "    return mse(ITE_true, ITE_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_learner(data):\n",
    "    treated_data, control_data = extract_treat_and_control_data(\n",
    "        data, data[\"T\"])\n",
    "    \n",
    "    # train u1\n",
    "    u1 = build_mlp()\n",
    "    X_treated = treated_data.drop([\"T\", \"Y\"], axis=1)\n",
    "    u1.fit(X_treated, treated_data[\"Y\"])\n",
    "    \n",
    "    # train u0\n",
    "    u0 = build_mlp()\n",
    "    X_control = control_data.drop([\"T\", \"Y\"], axis=1)\n",
    "    u0.fit(X_control, control_data[\"Y\"])\n",
    "    \n",
    "    # Generate potential outcome predictions\n",
    "    X = data.drop([\"T\", \"Y\"], axis=1)\n",
    "    y_1_predicted = u1.predict(X)\n",
    "    y_0_predicted = u0.predict(X)\n",
    "    \n",
    "    ITE_pred = y_1_predicted - y_0_predicted\n",
    "    \n",
    "    return ITE_pred, u1, u0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_learner(data):\n",
    "    # train u1\n",
    "    u = build_mlp()\n",
    "    X = data.drop(\"Y\", axis=1)\n",
    "    u.fit(X, data[\"Y\"])\n",
    "    \n",
    "    # Generate potential outcomes\n",
    "    X_under_treatment = X.copy()\n",
    "    X_under_treatment[\"T\"] = 1\n",
    "    \n",
    "    X_under_control = X.copy()\n",
    "    X_under_control[\"T\"] = 0\n",
    "    \n",
    "    y_1_predicted = u.predict(X_under_treatment)\n",
    "    y_0_predicted = u.predict(X_under_control)\n",
    "    y_1_predicted - y_0_predicted\n",
    "    \n",
    "    ITE_pred = y_1_predicted - y_0_predicted\n",
    "    \n",
    "    return  ITE_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_learner(data, u1=None, u0=None):\n",
    "    treated_data, control_data = extract_treat_and_control_data(\n",
    "        data, data[\"T\"])\n",
    "    X_treated = treated_data.drop([\"T\", \"Y\"], axis=1)\n",
    "    X_control = control_data.drop([\"T\", \"Y\"], axis=1)\n",
    "\n",
    "    if u1 is None:\n",
    "        # train u1\n",
    "        u1 = build_mlp()\n",
    "        u1.fit(X_treated, treated_data[\"Y\"])\n",
    "    \n",
    "    if u0 is None:\n",
    "        # train u0\n",
    "        u0 = build_mlp()\n",
    "        u0.fit(X_control, control_data[\"Y\"])\n",
    "    \n",
    "    # Find individual treatment effects for treated/controls\n",
    "    itet = treated_data[\"Y\"] - u0.predict(X_treated)\n",
    "    itec =  u1.predict(X_control) - control_data[\"Y\"]\n",
    "    \n",
    "    # Fit models to the treated and controls\n",
    "    te1 = build_mlp()\n",
    "    te1.fit(X_treated, itet)\n",
    "    \n",
    "    te0 = build_mlp()\n",
    "    te0.fit(X_control, itec)\n",
    "    \n",
    "    X = data.drop([\"T\", \"Y\"], axis=1)\n",
    "    te1_predicted = te1.predict(X)\n",
    "    te0_predicted = te0.predict(X)\n",
    "    \n",
    "    # Estimate prop scores\n",
    "    lm = LogisticRegression(solver=\"lbfgs\")\n",
    "    lm.fit(X, data[\"T\"])\n",
    "    prop_scores = lm.predict(X)\n",
    "    \n",
    "    # Down-weight observes which are likely to belong\n",
    "    # to other class.\n",
    "    te = prop_scores*te0_predicted + (1-prop_scores)*te1_predicted\n",
    "    \n",
    "    return te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'observed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4c74c04d40ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mITE_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore_ITE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITE_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITE_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'observed_data' is not defined"
     ]
    }
   ],
   "source": [
    "ITE_pred, _, _ = T_learner(observed_data)\n",
    "score_ITE(ITE_true, ITE_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'observed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dc7655ab8548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mITE_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore_ITE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITE_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITE_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'observed_data' is not defined"
     ]
    }
   ],
   "source": [
    "ITE_pred = S_learner(observed_data)\n",
    "score_ITE(ITE_true, ITE_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITE_pred = X_learner(observed_data)\n",
    "score_ITE(ITE_true, ITE_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(prop_score=0.5, n_covars=20, n_observations=50000):\n",
    "    observed_data, unobservable_data = generate_data(\n",
    "        prop_score=prop_score,\n",
    "        n_covars=n_covars,\n",
    "        n_observations=n_observations)\n",
    "    \n",
    "    ITE_true = unobservable_data[\"TE\"]\n",
    "    \n",
    "    # T learner\n",
    "    ITE_pred, u1, u0 = T_learner(observed_data)\n",
    "    T_loss = score_ITE(ITE_true, ITE_pred)\n",
    "    \n",
    "    # S learner\n",
    "    ITE_pred = S_learner(observed_data)\n",
    "    S_loss = score_ITE(ITE_true, ITE_pred)\n",
    "    \n",
    "    # X learner\n",
    "    ITE_pred = X_learner(observed_data, u1, u0)\n",
    "    X_loss = score_ITE(ITE_true, ITE_pred)\n",
    "    \n",
    "    return T_loss, S_loss, X_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_obs = np.logspace(3, 4, 6).astype(int)\n",
    "N_obs = [100000, 200000, 300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at n: 100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-0b490484f772>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(prop_score, n_covars, n_observations)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# X learner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mITE_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mX_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_ITE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITE_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITE_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bf5bce26c14c>\u001b[0m in \u001b[0;36mX_learner\u001b[0;34m(data, u1, u0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Estimate prop scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprop_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1606\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "N_trials = 1\n",
    "for n_obs in N_obs:\n",
    "    print(\"Running at n:\", n_obs)\n",
    "    trial_results = []\n",
    "    for _ in range(N_trials):\n",
    "        res = run_trial(prop_score=0.02, n_observations=n_obs)\n",
    "        trial_results.append(res)\n",
    "        \n",
    "    \n",
    "    trial_results = np.array(trial_results)\n",
    "    results.append(np.mean(trial_results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.array(results)\n",
    "names = [\"T learner\", \"S learner\", \"X learner\"]\n",
    "for i, name in enumerate(names):\n",
    "    plt.scatter(np.log(N_obs), np.log(results[:, i]), label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
